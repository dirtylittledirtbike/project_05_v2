{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import spacy\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and document tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all urls from posts\n",
    "\n",
    "extractor = URLExtract()\n",
    "def replace_urls(x):\n",
    "    urls = extractor.find_urls(x)\n",
    "    if urls:\n",
    "        x_new = replace_urls(x.replace(urls[0],''))\n",
    "        return x_new\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_the_donald.title.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading r/the_donald\n",
    "r_the_donald = pd.read_csv('data/the_donald_full.csv', low_memory=False)\n",
    "r_the_donald['date'] = pd.to_datetime(r_the_donald.created_utc, unit='s')\n",
    "r_the_donald['text_title'] = r_the_donald.title.fillna('') + ' ' + r_the_donald.selftext.fillna('')\n",
    "r_the_donald['text_title'] = r_the_donald.text_title.apply(lambda x: replace_urls(x))\n",
    "r_the_donald.text_title.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1178929, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_the_donald.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize original posts for r/depression\n",
    "donald_tokenized_posts = [gensim.utils.simple_preprocess(p) for p in r_the_donald.text_title if len(p) >= 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/the_donald: 798533\n"
     ]
    }
   ],
   "source": [
    "print('r/the_donald:',len(donald_tokenized_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from gensim.models.callbacks import CallbackAny2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a class to log our loss for each epoch\n",
    "# note that gensim has some issues/bugs with the compute loss parameter\n",
    "# so this is being used to loosely identify the elbow in our loss\n",
    "\n",
    "class LossLogger(CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "        self.epoch += 1\n",
    "        \n",
    "loss_logger = LossLogger()\n",
    "\n",
    "# also to speed things up we will want to use all available cores\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 11159144.0\n",
      "Loss after epoch 1: 8893936.0\n",
      "Loss after epoch 2: 8081706.0\n",
      "Loss after epoch 3: 7140054.0\n",
      "Loss after epoch 4: 5229868.0\n",
      "Loss after epoch 5: 5168140.0\n",
      "Loss after epoch 6: 5111432.0\n",
      "Loss after epoch 7: 5061340.0\n",
      "Loss after epoch 8: 4982492.0\n",
      "Loss after epoch 9: 5007932.0\n",
      "Loss after epoch 10: 1471588.0\n",
      "Loss after epoch 11: 272280.0\n",
      "Loss after epoch 12: 273304.0\n",
      "Loss after epoch 13: 269120.0\n",
      "Loss after epoch 14: 264264.0\n",
      "Loss after epoch 15: 268144.0\n",
      "Loss after epoch 16: 262648.0\n",
      "Loss after epoch 17: 256080.0\n",
      "Loss after epoch 18: 255136.0\n",
      "Loss after epoch 19: 249632.0\n",
      "Loss after epoch 20: 248176.0\n",
      "Loss after epoch 21: 247440.0\n",
      "Loss after epoch 22: 243176.0\n",
      "Loss after epoch 23: 237888.0\n",
      "Loss after epoch 24: 230432.0\n",
      "Loss after epoch 25: 230248.0\n",
      "Loss after epoch 26: 223160.0\n",
      "Loss after epoch 27: 218296.0\n",
      "Loss after epoch 28: 218168.0\n",
      "Loss after epoch 29: 216848.0\n",
      "Loss after epoch 30: 215160.0\n",
      "Loss after epoch 31: 211688.0\n",
      "Loss after epoch 32: 210328.0\n",
      "Loss after epoch 33: 204928.0\n",
      "Loss after epoch 34: 200520.0\n"
     ]
    }
   ],
   "source": [
    "# after looking at the data words that appear less than 9 times are predominantly uncommon mispellings\n",
    "# so our min count for r/depression will be 9 in the 10-15 range we see less mispellings/valid uncommon words\n",
    "# with r/depression data anything over 10 epochs will give good results\n",
    "\n",
    "r_the_donald_model = gensim.models.Word2Vec(\n",
    "                                            donald_tokenized_posts,\n",
    "                                            size=300,\n",
    "                                            window=5,\n",
    "                                            min_count=5,\n",
    "                                            sg=1,\n",
    "                                            callbacks=[loss_logger],\n",
    "                                            compute_loss=True,\n",
    "                                            iter=35,\n",
    "                                            workers=cores\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_the_donald_model.save(\"models/r_the_donald.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_anxiety_model.save(\"models/r_anxiety.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the learned word embeddings for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('media', 0.47440338134765625),\n",
       " ('platforms', 0.4521333873271942),\n",
       " ('smaca', 0.4504384994506836),\n",
       " ('censorship', 0.41543710231781006),\n",
       " ('garfunkel', 0.4153199791908264),\n",
       " ('mytaxcut', 0.41112202405929565),\n",
       " ('isolationism', 0.4109939634799957),\n",
       " ('justice', 0.4057742953300476),\n",
       " ('trumptown', 0.4027055501937866),\n",
       " ('giants', 0.3964461088180542)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_the_donald_model.wv.most_similar(['social'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['tired'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['love'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# anxiety[anxiety.selftext.str.contains(' reddit ')].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['social', 'media', 'account'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['river'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['hate'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_anxiety_model.wv.most_similar(positive=['psychiatrist'], negative=['prescribed'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['psychiatrist'], negative=['prescribed'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['comment'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_anxiety_model.wv.most_similar(positive=['comment'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['boy', 'woman'], negative=['man'],topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sideffects (insomnia libido), prescriptions(adderall, antidepressant/ssri)\n",
    "\n",
    "gender = king - queen , gender = man - woman\n",
    "\n",
    "king - x = man - woman\n",
    "man - woma - king = - x\n",
    "woman - man + king = x\n",
    "\n",
    "man + royal = king\n",
    "woman + royal = queen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['effects'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['appetite'],topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['appetite', 'antidepressants'], negative=['stimulants'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['appetite', 'ssris'], negative=['stimulants'],topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = model1.wv['libido'] + model1.wv['antidepressant']\n",
    "# model2.wv.most_similar(['girl'],topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# diff = model.wv['stimulants'] - model.wv['anxiety'] + model.wv['antidepressants']\n",
    "# model.wv.similar_by_vector(diff,topn=40)\n",
    "# model2.wv.most_similar(positive=['appetite', 'zoloft'], negative=['adderall'], topn=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(r_depression_model.wv.most_similar(positive=['guy', 'woman'], negative=['girl'], topn=10))\n",
    "print()\n",
    "print(r_depression_model.wv.most_similar(positive=['bad', 'happy'], negative=['good'], topn=10))\n",
    "# print(model2.wv.most_similar(positive=['yeezy', 'obama'], negative=['japan'], topn=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_depression_model.wv.most_similar(positive=['manga', 'america'], negative=['japan'], topn=20))\n",
    "print()\n",
    "print(r_depression_model.wv.most_similar(positive=['anime', 'america'], negative=['japan'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(r_anxiety_model.wv.most_similar(positive=['manga', 'america'], negative=['japan'], topn=20))\n",
    "print()\n",
    "print(r_anxiety_model.wv.most_similar(positive=['anime', 'america'], negative=['japan'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wt = r_depression_model.wv.most_similar(positive=['man', 'talks'], negative=['woman'], topn=30)\n",
    "mt = r_depression_model.wv.most_similar(positive=['woman', 'talks'], negative=['man'], topn=20)\n",
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = r_depression_model.wv.most_similar(positive=['guy', 'talks'], negative=['girl'], topn=20)\n",
    "mt = r_depression_model.wv.most_similar(positive=['guy', 'talks'], negative=['girl'], topn=20)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['dog', 'barks'], negative=['cat'],topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['girl', 'engineer'], negative=['guy'],topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model2.wv.most_similar(positive=['man', 'gives'], negative=['woman'], topn=10))\n",
    "wt = r_anxiety_model.wv.most_similar(positive=['man', 'talks'], negative=['woman'], topn=20)\n",
    "mt = r_anxiety_model.wv.most_similar(positive=['woman', 'talks'], negative=['man'], topn=20)\n",
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_anxiety_model.wv.most_similar(positive=['guy', 'gives'], negative=['girl'], topn=20))\n",
    "print()\n",
    "print(r_anxiety_model.wv.most_similar(positive=['guy', 'gives'], negative=['girl'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_depression_model.wv.most_similar(positive=['guy', 'gives'], negative=['girl'], topn=20))\n",
    "print()\n",
    "print(r_depression_model.wv.most_similar(positive=['girl', 'gives'], negative=['guy'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_depression_model.wv.most_similar(positive=['guy', 'talks'], negative=['girl'], topn=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_depression_model.wv.most_similar(positive=['guy', 'asks'], negative=['girl'], topn=15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt = r_depression_model.wv.most_similar(positive=['guy', 'talks'], negative=['girl'], topn=12)\n",
    "# mt = r_anxiety_model.wv.most_similar(positive=['guy', 'talks'], negative=['girl'], topn=12)\n",
    "\n",
    "wt = r_depression_model.wv.most_similar(positive=['anime', 'america'], negative=['japan'], topn=12)\n",
    "mt = r_anxiety_model.wv.most_similar(positive=['anime', 'america'], negative=['japan'], topn=12)\n",
    "\n",
    "funny_list = [[item[0], round(item[1], 4)] for item in mt]\n",
    "funny_list2 = [[item[0], round(item[1], 4)] for item in wt]\n",
    "\n",
    "\n",
    "x = [item[0] for item in funny_list]\n",
    "y = [item[1] for item in funny_list]\n",
    "\n",
    "x2 = [item[0] for item in funny_list2]\n",
    "y2 = [item[1] for item in funny_list2]\n",
    "\n",
    "plt.figure(figsize=[10, 7])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10, 8])\n",
    "plt.title('Man - Woman + Talks\\n', color='black', fontsize=13)\n",
    "ax.barh(x, y, color = 'salmon')\n",
    "plt.xlabel('Cosine Similarity', fontsize=12, color='black', fontname='Osaka')\n",
    "plt.grid(False)\n",
    "# plt.xlim([.24, .42])\n",
    "ax.axes.tick_params(axis=\"y\", colors='black', labelsize=12)\n",
    "ax.axes.tick_params(axis=\"x\", colors=\"black\", labelsize=12)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10, 7])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10, 8])\n",
    "plt.title('Man - Woman + Talks\\n', color='black', fontsize=13)\n",
    "ax.barh(x2, y2, color = 'salmon')\n",
    "plt.xlabel('Cosine Similarity', fontsize=12, color='black', fontname='Osaka')\n",
    "plt.grid(False)\n",
    "# plt.xlim([.24, .42])\n",
    "ax.axes.tick_params(axis=\"y\", colors='black', labelsize=12)\n",
    "ax.axes.tick_params(axis=\"x\", colors=\"black\", labelsize=12)\n",
    "# plt.savefig('MARKIPLIER.png', transparent=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['energy'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['insomnia'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(['circadian'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r_anxiety_model.wv.most_similar(['circadian'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['sleep'], negative=['insomnia'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.similar_by_vector(negative=['psychiatrist', 'prescribed'],topn=20)\n",
    "# model2.wv.most_similar(positive=['psychiatrist'], negative=['prescribed'], topn=20)\n",
    "# model2.wv.most_similar(positive=['addict'], negative=['drugs'], topn=20)\n",
    "r_depression_model.wv.most_similar(positive=['alcoholic'], negative=['alcohol'], topn=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_depression_model.wv.most_similar(positive=['alcoholic'], topn=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_anxiety_model.wv.most_similar(positive=['alcoholic'], negative=['alcohol'], topn=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_depression_model.wv.most_similar(positive=['sad', 'happy'], negative=['tears'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_anxiety_model.wv.most_similar(positive=['alcoholic'], topn=20))\n",
    "print()\n",
    "print(r_anxiety_model.wv.most_similar(positive=['addict'], negative=['drugs'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_depression_model.wv.most_similar(positive=['alcoholic'], topn=20))\n",
    "print()\n",
    "print(r_depression_model.wv.most_similar(positive=['addict'], negative=['drugs'], topn=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "# doc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# a = r_depression_model.wv['man']\n",
    "# b = r_depression_model.wv['woman']\n",
    "\n",
    "# c = r_depression_model.wv['asked']\n",
    "# d = r_depression_model.wv['told']\n",
    "\n",
    "\n",
    "\n",
    "# # a = np.array([-1,1])\n",
    "# # b = np.array([1,1])\n",
    "# x = a + c - b\n",
    "\n",
    "# x2 = r_depression_model.wv['therapist']\n",
    "# x3 = r_depression_model.wv.similar_by_vector(x)\n",
    "\n",
    "# # fig = plt.figure(figsize=[15,15])\n",
    "# # ax = ax.gca(projection='3d')\n",
    "# fig, ax = plt.subplots(figsize=[10, 8])\n",
    "# V = np.array([a, b])\n",
    "# origin = np.array([[0, 0],[0, 0]]) # origin point\n",
    "\n",
    "# ax.quiver(*origin, V[:,0], V[:,1], color=['r','b','g'], scale=1.2)\n",
    "# # plt.xlim([-.002, .002])\n",
    "# # plt.show()\n",
    "# # model.wv.similar_by_vector(x)\n",
    "\n",
    "# ax.axes.tick_params(axis=\"y\", colors='white', labelsize=10)\n",
    "# ax.axes.tick_params(axis=\"x\", colors=\"white\", labelsize=10)\n",
    "# plt.grid(False)\n",
    "# # plt.savefig('vecs11.png', transparent=True, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# text = data_copy.text_title\n",
    "# tokenized_self_text = [gensim.utils.simple_preprocess(d) for d in text]\n",
    "\n",
    "# author = data_copy.author\n",
    "# tokenized_title = [gensim.utils.simple_preprocess(d) for d in author]\n",
    "\n",
    "\n",
    "# tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "# tagged_data[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = []\n",
    "# for index, doc in enumerate(tokenized_self_text):\n",
    "#     tagged = TaggedDocument(words=doc, tags=[index])\n",
    "#     docs.append(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define parameters for doc2vec\n",
    "# doc_model = gensim.models.Doc2Vec(\n",
    "#                                   vector_size=300,\n",
    "#                                   window=5,\n",
    "#                                   min_count=5,\n",
    "#                                   workers=cores,\n",
    "#                                   epochs=10,\n",
    "#                                   alpha=.025,\n",
    "#                                   min_alpha = 0.0001)\n",
    "# doc_model.build_vocab(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# doc_model.train(docs, total_examples=doc_model.corpus_count, epochs=doc_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = '''\n",
    "# Slowly isolating myself\n",
    "# Sorry just wanted to say something to anyone really\n",
    "# but i used to talk to a couple people about my issues\n",
    "# and how i was doing but i feel like everytime i do i\n",
    "# annoy them and that im being boring or just a pain to be around.\n",
    "# I always overthink situations and im probably doing the same here but\n",
    "# im sat here just wishing i could talk to those i trust but i\n",
    "# also dont want to be a burden all the time. I cant talk to many people\n",
    "# and i struggle to talk to new people. Also there some of my best friends\n",
    "# i dont want to lose them but i also know i need to express how I feel.\n",
    "# Thank you for reading my rambling if you did..\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing = gensim.utils.simple_preprocess(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferred_vector = doc_model.infer_vector(testing)\n",
    "# sims = doc_model.docvecs.most_similar([inferred_vector], topn=len(doc_model.docvecs))\n",
    "# sims[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing = '''\n",
    "# i really need advice on my medication i just starting taking zoloft'''\n",
    "\n",
    "# testing = gensim.utils.simple_preprocess(testing)\n",
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_df = pd.DataFrame(doc_model.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc_model.docvecs.vectors_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our word embeddings to a tensorflow friendly format so we can load embeddings into embedding projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = []\n",
    "counts =[]\n",
    "w2v = gensim.models.Word2Vec.load(\"models/r_the_donald.model\")\n",
    "for index in range(len(w2v.wv.index2word)):\n",
    "    word = w2v.wv.index2word[index]\n",
    "    words.append(word)\n",
    "    counts.append(w2v.wv.vocab[word].count)\n",
    "    \n",
    "pd.DataFrame({'word':words, 'count':counts}).to_csv('/Users/collinswestnedge/programming/project_05/tensor_data/r_the_donald_meta.tsv', index=False,sep='\\t' )\n",
    "\n",
    "import io\n",
    "\n",
    "# Vector file, `\\t` seperated the vectors and `\\n` seperate the words\n",
    "# \"\"\"\n",
    "# 0.1\\t0.2\\t0.5\\t0.9\n",
    "# 0.2\\t0.1\\t5.0\\t0.2\n",
    "# 0.4\\t0.1\\t7.0\\t0.8\n",
    "# \"\"\"\n",
    "\n",
    "path2 = '/Users/collinswestnedge/programming/project_05/tensor_data/r_the_donald_'\n",
    "\n",
    "out_v = io.open(path2+'vecs.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Meta data file, `\\n` seperated word\n",
    "# \"\"\"\n",
    "# token1\n",
    "# token2\n",
    "# token3\n",
    "# \"\"\"\n",
    "# out_m = io.open(path2+'meta.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "# Write meta file and vector file\n",
    "for index in range(len(w2v.wv.index2word)):\n",
    "    word = w2v.wv.index2word[index]\n",
    "    vec = w2v.wv.vectors[index]\n",
    "    count = w2v.wv.vocab[word].count\n",
    "#     out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "out_v.close()\n",
    "# out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "unique_words = defaultdict(int)\n",
    "\n",
    "for index in range(len(w2v.wv.index2word)):\n",
    "    word = w2v.wv.index2word[index]\n",
    "    unique_words[w2v.wv.index2word[index]] = w2v.wv.vocab[word].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining co-occurrences for schizophrenic and psychotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_schizophrenic = (dep_post_comments[(dep_post_comments.body.isna() == False)&\n",
    "                                            (dep_post_comments.body.str.contains('schizophrenic'))]\n",
    "                          .body)\n",
    "\n",
    "posts_schizophrenic = (depression[(depression.text_title.isna() == False)&\n",
    "                                            (depression.text_title.str.contains('schizophrenic'))]\n",
    "                       .text_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a very unaggressive tokenization so we may have to do more later.\n",
    "\n",
    "# posts_schizophrenic_tokenized = [gensim.utils.simple_preprocess(p) for p in posts_schizophrenic]\n",
    "# comments_schizophrenia_tokenized = [gensim.utils.simple_preprocess(p) for p in comments_schizophrenia]\n",
    "# schizophrenic_tokenized = posts_schizophrenic_tokenized + comments_schizophrenia_tokenized\n",
    "\n",
    "schizophrenic_full = pd.concat([posts_schizophrenic,comments_schizophrenic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def process_text(nlp, text, pos_list, lemma=False):\n",
    "\n",
    "    text_full = [] \n",
    "    for doc in nlp.pipe(text, disable=['parser', 'ner', 'tagger']):\n",
    "        # if part of speech list isnt empty return matches for pos\n",
    "        if pos_list:\n",
    "            tokens = [(ent.pos_) for ent in doc if not ent.is_stop and not ent.is_punct and ent.pos_ in pos_list]\n",
    "            cleaned_text = \" \".join(tokens)\n",
    "            text_full.append(cleaned_text)\n",
    "        elif lemma == True:\n",
    "            tokens = [(ent.lemma_) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "            cleaned_text = \" \".join(tokens)\n",
    "            text_full.append(cleaned_text)\n",
    "        else:\n",
    "            tokens = [(ent.text) for ent in doc if not ent.is_stop and not ent.is_punct]\n",
    "            cleaned_text = \" \".join(tokens)\n",
    "            text_full.append(cleaned_text)\n",
    "            \n",
    "    return text_full\n",
    "\n",
    "corp = schizophrenic_full\n",
    "# corp = useable_text.text_title\n",
    "processed_text = process_text(nlp, corp, pos_list=[], lemma=False)\n",
    "len(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "tokenized_text = [doc.split() for doc in processed_text]\n",
    "terms_bigram = [list(bigrams(doc)) for doc in tokenized_text]\n",
    "\n",
    "schizophrenic_bigrams = []\n",
    "for item in terms_bigram:\n",
    "    for bigram in item:\n",
    "        if 'schizophrenic' in list(bigram):\n",
    "            schizophrenic_bigrams.append(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts = collections.Counter(schizophrenic_bigrams)\n",
    "bigram_counts.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('father')].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('father')].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('father')].values[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('father')].values[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('homicidal')].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('homicidal')].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('homicidal')].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('psychopath')].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schizophrenic_full[schizophrenic_full.str.contains('psychopath')].values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_schizophrenic = (dep_post_comments[(dep_post_comments.body.isna() == False)&\n",
    "                                            (dep_post_comments.body.str.contains('schizophrenic'))]\n",
    "                          [['created_utc_comment','body']])\n",
    "\n",
    "posts_schizophrenic = (depression[(depression.text_title.isna() == False)&\n",
    "                                            (depression.text_title.str.contains('schizophrenic'))]\n",
    "                       [['date','text_title']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_schizophrenic['date'] = pd.to_datetime(comments_schizophrenic.created_utc_comment, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_schizophrenic.groupby(posts_schizophrenic.date.dt.year).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depression[depression.selftext.str.contains('the_donald')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
